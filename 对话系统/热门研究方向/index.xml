<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NLP简介 on 知几小博客</title>
    <link>https://zhijiblog.github.io/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/%E7%83%AD%E9%97%A8%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91/</link>
    <description>Recent content in NLP简介 on 知几小博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 21 Sep 2020 16:09:16 +0800</lastBuildDate><atom:link href="https://zhijiblog.github.io/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/%E7%83%AD%E9%97%A8%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>热门研究方向</title>
      <link>https://zhijiblog.github.io/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/%E7%83%AD%E9%97%A8%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91/%E7%83%AD%E9%97%A8%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91/</link>
      <pubDate>Fri, 18 Sep 2020 10:04:15 +0800</pubDate>
      
      <guid>https://zhijiblog.github.io/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/%E7%83%AD%E9%97%A8%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91/%E7%83%AD%E9%97%A8%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91/</guid>
      <description>2.1 环境搭建 目前运用朴素贝叶斯实现的文本分类框架有很多，例如TextBlob、SnowNLP、PaddleHub等。本次项目使用了SnowNLP这个框架。因为这个框架是针对中文文本编写的，且使用起来比较方便。SnowNLP的源码参见https://github.com/isnowfy/snownlp。
具体使用框架的时候，首先需要获取业务类语料库和闲聊类语料库。该项目使用的语料库是从有记录以来，所有的已分类好的提问记录。其中业务类包含437246条真实语料，闲聊类包含149636条真实语料。这两个语料库需要分成两个txt文件保存至项目目录下：
   业务类.txt 闲聊类.txt     升级段位可以获得头像框吗 熊出没之春日对对碰是什么类型的动漫   屏蔽的好友在哪里找回来 007皇家赌场的拍摄日期是那年？   好友之间怎么观战 马绍尔群岛的首都是哪里？   怎么切换回原来的帐号 吴宗宪的出生地是   历史战绩能保存几天 真三国无双7中有几个势力？   两人组队怎么退出房间 祝你做个好梦，睡个好觉。   圆形升级核心从哪儿获得 我说要考试了怎么办   …… ……    2.2 训练集优化 这些原始的语料库只经过了简单的去重，保证了彼此之间不会重复。为了进一步去除语料库中的重复内容，考虑前面提到的去除停用词方法，把句子里的停用词全部去掉，再做一次去重。这样能够进一步降低语料库的冗余性。例如如下两个句子：
 绝版 / 纪念 / 头像框 / 怎么 / 获得 绝版 / 纪念 / 头像框 / 哪里 / 可以 / 获得  两个句子中标红的词语均为停用词，删除之后两个句子都变成了：</description>
    </item>
    
  </channel>
</rss>
